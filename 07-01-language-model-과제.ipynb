{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07-01-language-model-과제.ipynb","provenance":[],"collapsed_sections":["6dfJPT-2XMTB","JHkHg6XAXoyK","XwriCkq_R1Lc","3myBX8hNEH1u","L2vJmIBt3-ci","_dBAGBHE3-ck","MFWK8EvH3-cp","g2rxLFrL3-cq"],"authorship_tag":"ABX9TyPgvWF1ppWq1xy6eUxi/+Gc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6dfJPT-2XMTB"},"source":["# Install"]},{"cell_type":"code","metadata":{"id":"a193aGJWVaqb"},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JHkHg6XAXoyK"},"source":["# Evn"]},{"cell_type":"code","metadata":{"id":"WkYXFwcBXJDG"},"source":["import os\n","import random\n","import shutil\n","import json\n","import zipfile\n","import math\n","import copy\n","import collections\n","import re\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import sentencepiece as spm\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvjyruUlXtlR"},"source":["# random seed initialize\n","random_seed = 1234\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","tf.random.set_seed(random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BC3fXkhdYcYt"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVRdxYReYeQj"},"source":["# google drive mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"byCIiLJBbFHh"},"source":["# data dir\n","data_dir = '/content/drive/MyDrive/Data/nlp'\n","os.listdir(data_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Ru56YS3-SME"},"source":["# korean wiki dir\n","kowiki_dir = os.path.join(data_dir, 'kowiki')\n","if not os.path.exists(kowiki_dir):\n","    os.makedirs(kowiki_dir)\n","os.listdir(kowiki_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XwriCkq_R1Lc"},"source":["# Vocabulary & config"]},{"cell_type":"code","metadata":{"id":"2H0BLydCb7lg"},"source":["# vocab loading\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(os.path.join(data_dir, 'ko_32000.model'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ETZ19flTRmt"},"source":["n_vocab = len(vocab)  # number of vocabulary\n","n_seq = 256  # number of sequence\n","d_model = 256  # dimension of model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3myBX8hNEH1u"},"source":["# 모델링"]},{"cell_type":"code","metadata":{"id":"SobekkcjEX_P"},"source":["def build_model(n_vocab, d_model, n_seq):\n","    \"\"\"\n","    문장 유사도 비교 모델\n","    :param n_vocab: vocabulary 단어 수\n","    :param d_model: 단어를 의미하는 벡터의 차원 수\n","    :param n_seq: 문장 길이 (단어 수)\n","    \"\"\"\n","    inputs = tf.keras.layers.Input((n_seq,))  # (bs, n_seq)\n","    # 입력 단어를 vector로 변환\n","    embedding = tf.keras.layers.Embedding(n_vocab, d_model)\n","    hidden = embedding(inputs)  # (bs, n_seq, d_model)\n","    # LSTM\n","    lstm = tf.keras.layers.LSTM(units=d_model * 2, return_sequences=True)\n","    hidden = lstm(hidden)  # (bs, n_seq, d_model * 2)\n","    # 다음단어 확률 분포\n","    dense = tf.keras.layers.Dense(n_vocab, activation=tf.nn.softmax)\n","    outputs = dense(hidden)\n","    # 학습할 모델 선언\n","    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L2vJmIBt3-ci"},"source":["# All Data Project"]},{"cell_type":"markdown","metadata":{"id":"_dBAGBHE3-ck"},"source":["## Data\n"]},{"cell_type":"code","metadata":{"id":"X7Jbbcdm3-ck"},"source":["def load_data(vocab, n_seq):\n","    \"\"\"\n","    Language Model 학습 데이터 생성\n","    :param vocab: vocabulary object\n","    :param n_seq: number of sequence\n","    :return inputs_1: input data 1\n","    :return inputs_2: input data 2\n","    :return labels: label data\n","    \"\"\"\n","    # line 수 조회\n","    n_line = 0\n","    with open(os.path.join(kowiki_dir, 'kowiki_lm.json')) as f:\n","        for line in f:\n","            n_line += 1\n","    # 최대 100,000개 데이터\n","    n_data = min(n_line, 100000)\n","    # 빈 데이터 생성\n","    inputs = np.zeros((n_data, n_seq)).astype(np.int32)\n","    labels = np.zeros((n_data, n_seq)).astype(np.int32)\n","\n","    with open(os.path.join(kowiki_dir, 'kowiki_lm.json')) as f:\n","        for i, line in enumerate(tqdm(f, total=n_data)):\n","            if i >= n_data:\n","                break\n","            data = json.loads(line)\n","            token_id = [vocab.piece_to_id(p) for p in data['token']]\n","            # input id\n","            input_id = [vocab.bos_id()] + token_id\n","            input_id += [0] * (n_seq - len(input_id))\n","            # label id\n","            label_id = token_id + [vocab.eos_id()]\n","            label_id += [0] * (n_seq - len(label_id))\n","            # 값 저장\n","            inputs[i] = input_id\n","            labels[i] = label_id\n","\n","    return inputs, labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3P_qk633-cl"},"source":["# train data 생성\n","train_inputs, train_labels = load_data(vocab, n_seq)\n","train_inputs, train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFWK8EvH3-cp"},"source":["## Loss & Acc"]},{"cell_type":"code","metadata":{"id":"3cpcM1MW3-cp"},"source":["def lm_loss(y_true, y_pred):\n","    \"\"\"\n","    pad 부분을 제외하고 loss를 계산하는 함수\n","    :param y_true: 정답\n","    :param y_pred: 예측 값\n","    :retrun loss: pad 부분이 제외된 loss 값\n","    \"\"\"\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n","    mask = tf.not_equal(y_true, 0)\n","    mask = tf.cast(mask, tf.float32)\n","    loss *= mask\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xt7wUUf53-cp"},"source":["def lm_acc(y_true, y_pred):\n","    \"\"\"\n","    pad 부분을 제외하고 accuracy를 계산하는 함수\n","    :param y_true: 정답\n","    :param y_pred: 예측 값\n","    :retrun loss: pad 부분이 제외된 accuracy 값\n","    \"\"\"\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred_class = tf.cast(tf.argmax(y_pred, axis=-1), tf.float32)\n","    matches = tf.cast(tf.equal(y_true, y_pred_class), tf.float32)\n","    mask = tf.not_equal(y_true, 0)\n","    mask = tf.cast(mask, tf.float32)\n","    matches *= mask\n","    accuracy = tf.reduce_sum(matches) / tf.maximum(tf.reduce_sum(mask), 1)\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g2rxLFrL3-cq"},"source":["## 학습"]},{"cell_type":"code","metadata":{"id":"E45XLFFC3-cq"},"source":["# 모델 loss, optimizer, metric 정의\n","model.compile(loss=lm_loss, optimizer='adam', metrics=[lm_acc])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Js_YBU2l3-cq"},"source":["# early stopping\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='lm_acc', patience=5)\n","# save weights callback\n","save_weights = tf.keras.callbacks.ModelCheckpoint(os.path.join(kowiki_dir, 'lm.hdf5'),\n","                                                  monitor='lm_acc',\n","                                                  verbose=1,\n","                                                  save_best_only=True,\n","                                                  mode=\"max\",\n","                                                  save_freq=\"epoch\",\n","                                                  save_weights_only=True)\n","# csv logger\n","csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(kowiki_dir, 'lm.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mQqvywUG3-cq"},"source":["# 모델 학습\n","history = model.fit(train_inputs,\n","                    train_labels,\n","                    epochs=2,\n","                    batch_size=64,  # oom이 발생하면 값을 줄여주세요.\n","                    callbacks=[early_stopping, save_weights, csv_logger])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EttHWg_w3-cr"},"source":["plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['lm_acc'], 'g-', label='acc')\n","plt.xlabel('Epoch')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}